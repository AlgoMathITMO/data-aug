{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic users, items, history datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "users_df = pd.DataFrame(data=np.random.normal(0, 1, size=(1000, 35)), columns=[f'user_attr_{i}' for i in range(35)])\n",
    "items_df = pd.DataFrame(data=np.random.normal(1, 1, size=(200, 20)), columns=[f'item_attr_{i}' for i in range(20)])\n",
    "users_df['user_id'] = np.arange(len(users_df))\n",
    "items_df['item_id'] = np.arange(len(items_df))\n",
    "history_df = pd.DataFrame()\n",
    "history_df['user_id'] = np.random.randint(0, 1000, size=3000)\n",
    "history_df['item_id'] = np.random.randint(0, 200, size=3000)\n",
    "history_df['rating'] = np.random.randint(0, 5, size=3000)\n",
    "history_df = history_df.drop_duplicates(subset=['user_id', 'item_id'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-08 12:13:56 I deeptables.m.deeptable.py 338 - X.Shape=(2979, 55), y.Shape=(2979,), batch_size=64, config=ModelConfig(name='conf-1', nets=['linear', 'fm_nets', 'dnn_nets'], categorical_columns='auto', exclude_columns=[], task='auto', pos_label=None, metrics=['accuracy'], auto_categorize=False, cat_exponent=0.5, cat_remain_numeric=True, auto_encode_label=True, auto_imputation=True, auto_discrete=True, auto_discard_unique=True, apply_gbm_features=False, gbm_params={}, gbm_feature_type='embedding', fixed_embedding_dim=True, embeddings_output_dim=4, embeddings_initializer='uniform', embeddings_regularizer=None, embeddings_activity_regularizer=None, dense_dropout=0, embedding_dropout=0.3, stacking_op='add', output_use_bias=True, apply_class_weight=False, optimizer='RMSprop', loss='auto', dnn_params={'dnn_activation': 'relu'}, autoint_params={'num_attention': 3, 'num_heads': 1, 'dropout_rate': 0, 'use_residual': True}, fgcnn_params={'fg_filters': (14, 16), 'fg_heights': (7, 7), 'fg_pool_heights': (2, 2), 'fg_new_feat_filters': (2, 2)}, fibinet_params={'senet_pooling_op': 'mean', 'senet_reduction_ratio': 3, 'bilinear_type': 'field_interaction'}, cross_params={'num_cross_layer': 4}, pnn_params={'outer_product_kernel_type': 'mat'}, afm_params={'attention_factor': 4, 'dropout_rate': 0}, cin_params={'cross_layer_size': (128, 128), 'activation': 'relu', 'use_residual': False, 'use_bias': False, 'direct': False, 'reduce_D': False}, home_dir='./models/tmp', monitor_metric=None, earlystopping_patience=20, earlystopping_mode='auto', gpu_usage_strategy='memory_growth', distribute_strategy=None, var_len_categorical_columns=None)\n",
      "06-08 12:13:56 I deeptables.m.deeptable.py 339 - metrics:['accuracy']\n",
      "06-08 12:13:56 I hypernets.t.toolbox.py 346 - 5 class detected, inferred as a [multiclass classification] task\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 261 - Preparing features...\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 336 - Preparing features taken 0.007004976272583008s\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 341 - Data imputation...\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 383 - Imputation taken 0.008569002151489258s\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 388 - Categorical encoding...\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 393 - Categorical encoding taken 0.00034809112548828125s\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 398 - Data discretization...\n",
      "06-08 12:13:56 I hypernets.t.sklearn_ex.py 682 - 55 variables to discrete.\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 404 - Discretization taken 0.15564179420471191s\n",
      "06-08 12:13:56 I deeptables.m.preprocessor.py 196 - fit_transform taken 0.20563101768493652s\n",
      "06-08 12:13:56 I deeptables.m.deeptable.py 354 - Training...\n",
      "06-08 12:13:56 I deeptables.m.deeptable.py 752 - Injected a callback [EarlyStopping]. monitor:val_accuracy, patience:20, mode:max\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "06-08 12:13:58 I deeptables.u.dataset_generator.py 240 - create dataset generator with _TFDGForPandas, batch_size=64, shuffle=True, drop_remainder=True\n",
      "06-08 12:13:58 I deeptables.u.dataset_generator.py 240 - create dataset generator with _TFDGForPandas, batch_size=64, shuffle=True, drop_remainder=True\n",
      "06-08 12:13:58 I deeptables.m.deepmodel.py 231 - Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 12:13:57.088401: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-08 12:13:58.227281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 26475 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-08 12:13:58 I deeptables.m.deepmodel.py 287 - >>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (55)', 'input_continuous_all: (55)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "output_dims: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 275)\n",
      "---------------------------------------------------------\n",
      "nets: ['linear', 'fm_nets', 'dnn_nets']\n",
      "---------------------------------------------------------\n",
      "linear: input_shape (None, 110), output_shape (None, 1)\n",
      "fm: input_shape (None, 55, 4), output_shape (None, 1)\n",
      "dnn: input_shape (None, 275), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: softmax, output_shape: (None, 5), use_bias: True\n",
      "loss: categorical_crossentropy\n",
      "optimizer: RMSprop\n",
      "---------------------------------------------------------\n",
      "\n",
      "06-08 12:13:58 I deeptables.m.deepmodel.py 105 - training...\n",
      "Epoch 1/100\n",
      " 7/37 [====>.........................] - ETA: 0s - loss: 1.8914 - accuracy: 0.1830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 12:14:05.086734: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 7s 29ms/step - loss: 1.8106 - accuracy: 0.1862 - val_loss: 1.7435 - val_accuracy: 0.1836\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 1.6342 - accuracy: 0.2175 - val_loss: 1.6940 - val_accuracy: 0.1875\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.5853 - accuracy: 0.2356 - val_loss: 1.6747 - val_accuracy: 0.1875\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 1.5442 - accuracy: 0.2669 - val_loss: 1.6618 - val_accuracy: 0.2051\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 1.5171 - accuracy: 0.2724 - val_loss: 1.6656 - val_accuracy: 0.2031\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.4812 - accuracy: 0.2931 - val_loss: 1.6915 - val_accuracy: 0.2383\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.4624 - accuracy: 0.3197 - val_loss: 1.6726 - val_accuracy: 0.2070\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.4298 - accuracy: 0.3028 - val_loss: 1.6786 - val_accuracy: 0.2109\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.4063 - accuracy: 0.3247 - val_loss: 1.6802 - val_accuracy: 0.1914\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.3854 - accuracy: 0.3340 - val_loss: 1.6854 - val_accuracy: 0.1973\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.3613 - accuracy: 0.3505 - val_loss: 1.6833 - val_accuracy: 0.2148\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.3344 - accuracy: 0.3492 - val_loss: 1.7194 - val_accuracy: 0.1855\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.3082 - accuracy: 0.3746 - val_loss: 1.7492 - val_accuracy: 0.2129\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.3031 - accuracy: 0.3653 - val_loss: 1.7825 - val_accuracy: 0.1855\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.2684 - accuracy: 0.3771 - val_loss: 1.8293 - val_accuracy: 0.1777\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 1.2463 - accuracy: 0.3763 - val_loss: 1.8414 - val_accuracy: 0.1953\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.2211 - accuracy: 0.3999 - val_loss: 1.8595 - val_accuracy: 0.1953\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.2082 - accuracy: 0.4054 - val_loss: 1.9097 - val_accuracy: 0.1797\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1853 - accuracy: 0.3906 - val_loss: 1.9458 - val_accuracy: 0.1816\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1.1730 - accuracy: 0.3986 - val_loss: 2.0571 - val_accuracy: 0.2051\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 1.1597 - accuracy: 0.4113 - val_loss: 2.0190 - val_accuracy: 0.2207\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.1452 - accuracy: 0.4096 - val_loss: 2.1492 - val_accuracy: 0.1953\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.1318 - accuracy: 0.4143 - val_loss: 2.1322 - val_accuracy: 0.2129\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.1122 - accuracy: 0.4244 - val_loss: 2.1506 - val_accuracy: 0.1973\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 1.1051 - accuracy: 0.4261 - val_loss: 2.1480 - val_accuracy: 0.1953\n",
      "Epoch 26/100\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 1.0710 - accuracy: 0.4315Restoring model weights from the end of the best epoch: 6.\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 1.0723 - accuracy: 0.4291 - val_loss: 2.1868 - val_accuracy: 0.1914\n",
      "Epoch 26: early stopping\n",
      "06-08 12:14:24 I deeptables.m.deepmodel.py 122 - Training finished.\n",
      "06-08 12:14:24 I deeptables.m.deeptable.py 370 - Training finished.\n",
      "06-08 12:14:24 I deeptables.m.deeptable.py 704 - Model has been saved to:./models/tmp/dt_20220608121356_linear_fm_nets_dnn_nets/linear+fm_nets+dnn_nets.h5\n"
     ]
    }
   ],
   "source": [
    "from simulator.modules import NoiseResponse, ResponseFunctionSim, ConstantResponseHeuristic\n",
    "from deeptables.models.deeptable import ModelConfig\n",
    "from deeptables.models import deepnets\n",
    "from deeptables.models import deeptable\n",
    "\n",
    "\n",
    "deepfm_conf = ModelConfig(\n",
    "            nets=deepnets.DeepFM,\n",
    "            optimizer='RMSprop',\n",
    "            auto_discrete=True,\n",
    "            home_dir='./models/tmp',\n",
    "            earlystopping_patience=20,\n",
    "            dnn_params={'dnn_activation': 'relu'}\n",
    "        )\n",
    "deepfm = deeptable.DeepTable(config=deepfm_conf)\n",
    "\n",
    "cross_join_df = pd.merge(history_df, users_df, on='user_id', how='left')\n",
    "cross_join_df = pd.merge(cross_join_df, items_df, on='item_id', how='left')\n",
    "\n",
    "deepfm.fit(\n",
    "    cross_join_df.drop(['user_id', 'item_id', 'rating'], axis=1),\n",
    "    cross_join_df['rating'],\n",
    "    epochs=100,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "m1 = NoiseResponse(mu=1.0, sigma=1.0)\n",
    "m2 = ConstantResponseHeuristic(value=0.0)\n",
    "\n",
    "response_func = ResponseFunctionSim([m1, m2, deepfm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a92c2c18-829e-42b2-a1f4-0040c4c82202/assets\n"
     ]
    }
   ],
   "source": [
    "from simulator.utils import save\n",
    "\n",
    "save(response_func, 'models/demo_response.m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynEvaRec generator training and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator.modules import SDVGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "user_gen = SDVGenerator(model='gaussiancopula')\n",
    "item_gen = SDVGenerator(model='gaussiancopula')\n",
    "\n",
    "user_gen.fit(data=users_df.drop(['user_id'], axis=1))\n",
    "item_gen.fit(data=items_df.drop(['item_id'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_attr_0</th>\n",
       "      <th>user_attr_1</th>\n",
       "      <th>user_attr_2</th>\n",
       "      <th>user_attr_3</th>\n",
       "      <th>user_attr_4</th>\n",
       "      <th>user_attr_5</th>\n",
       "      <th>user_attr_6</th>\n",
       "      <th>user_attr_7</th>\n",
       "      <th>user_attr_8</th>\n",
       "      <th>user_attr_9</th>\n",
       "      <th>user_attr_10</th>\n",
       "      <th>user_attr_11</th>\n",
       "      <th>user_attr_12</th>\n",
       "      <th>user_attr_13</th>\n",
       "      <th>user_attr_14</th>\n",
       "      <th>user_attr_15</th>\n",
       "      <th>user_attr_16</th>\n",
       "      <th>user_attr_17</th>\n",
       "      <th>user_attr_18</th>\n",
       "      <th>user_attr_19</th>\n",
       "      <th>user_attr_20</th>\n",
       "      <th>user_attr_21</th>\n",
       "      <th>user_attr_22</th>\n",
       "      <th>user_attr_23</th>\n",
       "      <th>user_attr_24</th>\n",
       "      <th>user_attr_25</th>\n",
       "      <th>user_attr_26</th>\n",
       "      <th>user_attr_27</th>\n",
       "      <th>user_attr_28</th>\n",
       "      <th>user_attr_29</th>\n",
       "      <th>user_attr_30</th>\n",
       "      <th>user_attr_31</th>\n",
       "      <th>user_attr_32</th>\n",
       "      <th>user_attr_33</th>\n",
       "      <th>user_attr_34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.841159</td>\n",
       "      <td>-1.130349</td>\n",
       "      <td>-0.562767</td>\n",
       "      <td>-1.436658</td>\n",
       "      <td>-0.431905</td>\n",
       "      <td>0.862523</td>\n",
       "      <td>-0.477934</td>\n",
       "      <td>-1.569757</td>\n",
       "      <td>0.065317</td>\n",
       "      <td>-0.317478</td>\n",
       "      <td>0.930838</td>\n",
       "      <td>0.899253</td>\n",
       "      <td>-0.971943</td>\n",
       "      <td>-0.003831</td>\n",
       "      <td>-0.066607</td>\n",
       "      <td>-0.159761</td>\n",
       "      <td>1.120148</td>\n",
       "      <td>1.699936</td>\n",
       "      <td>1.498054</td>\n",
       "      <td>-0.532680</td>\n",
       "      <td>1.661771</td>\n",
       "      <td>0.221920</td>\n",
       "      <td>-0.084877</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>-0.125709</td>\n",
       "      <td>0.651412</td>\n",
       "      <td>-0.535483</td>\n",
       "      <td>0.150738</td>\n",
       "      <td>-0.012269</td>\n",
       "      <td>-1.137382</td>\n",
       "      <td>-0.476427</td>\n",
       "      <td>-2.797294</td>\n",
       "      <td>0.663258</td>\n",
       "      <td>-0.416740</td>\n",
       "      <td>-0.193871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.830372</td>\n",
       "      <td>0.358775</td>\n",
       "      <td>-0.790639</td>\n",
       "      <td>-0.405580</td>\n",
       "      <td>0.317278</td>\n",
       "      <td>-0.581364</td>\n",
       "      <td>-0.241973</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>-0.876017</td>\n",
       "      <td>-1.523888</td>\n",
       "      <td>0.934970</td>\n",
       "      <td>0.529797</td>\n",
       "      <td>-1.401530</td>\n",
       "      <td>-1.754575</td>\n",
       "      <td>0.763509</td>\n",
       "      <td>-1.114828</td>\n",
       "      <td>-2.029288</td>\n",
       "      <td>-0.428042</td>\n",
       "      <td>-1.166084</td>\n",
       "      <td>-0.093582</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.102403</td>\n",
       "      <td>0.727626</td>\n",
       "      <td>-0.378074</td>\n",
       "      <td>-0.636578</td>\n",
       "      <td>-1.313639</td>\n",
       "      <td>1.653801</td>\n",
       "      <td>-1.654276</td>\n",
       "      <td>-2.215451</td>\n",
       "      <td>-1.174355</td>\n",
       "      <td>-0.620082</td>\n",
       "      <td>-0.029469</td>\n",
       "      <td>-0.648945</td>\n",
       "      <td>0.433497</td>\n",
       "      <td>-0.167933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.216478</td>\n",
       "      <td>-1.453142</td>\n",
       "      <td>0.288821</td>\n",
       "      <td>-1.180521</td>\n",
       "      <td>2.225587</td>\n",
       "      <td>-0.728381</td>\n",
       "      <td>-1.003061</td>\n",
       "      <td>-0.234521</td>\n",
       "      <td>-1.208059</td>\n",
       "      <td>0.083634</td>\n",
       "      <td>-0.617756</td>\n",
       "      <td>-0.935496</td>\n",
       "      <td>-0.422625</td>\n",
       "      <td>-1.227134</td>\n",
       "      <td>0.016350</td>\n",
       "      <td>0.542612</td>\n",
       "      <td>-0.192226</td>\n",
       "      <td>-0.398528</td>\n",
       "      <td>-0.479267</td>\n",
       "      <td>2.380701</td>\n",
       "      <td>-1.954038</td>\n",
       "      <td>-0.600726</td>\n",
       "      <td>-1.394947</td>\n",
       "      <td>-1.377155</td>\n",
       "      <td>0.569841</td>\n",
       "      <td>0.748014</td>\n",
       "      <td>-0.349937</td>\n",
       "      <td>0.195864</td>\n",
       "      <td>-0.617014</td>\n",
       "      <td>-0.340315</td>\n",
       "      <td>-1.584362</td>\n",
       "      <td>-0.227072</td>\n",
       "      <td>-0.131698</td>\n",
       "      <td>1.296526</td>\n",
       "      <td>-0.738848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.308584</td>\n",
       "      <td>0.786508</td>\n",
       "      <td>-1.091464</td>\n",
       "      <td>0.800473</td>\n",
       "      <td>-0.134954</td>\n",
       "      <td>1.975992</td>\n",
       "      <td>2.134923</td>\n",
       "      <td>-0.310742</td>\n",
       "      <td>2.451551</td>\n",
       "      <td>2.867538</td>\n",
       "      <td>0.551122</td>\n",
       "      <td>-1.095965</td>\n",
       "      <td>0.318201</td>\n",
       "      <td>0.199045</td>\n",
       "      <td>0.493003</td>\n",
       "      <td>0.066637</td>\n",
       "      <td>-2.010671</td>\n",
       "      <td>0.082334</td>\n",
       "      <td>1.057195</td>\n",
       "      <td>1.455160</td>\n",
       "      <td>-0.187629</td>\n",
       "      <td>-0.071992</td>\n",
       "      <td>0.377811</td>\n",
       "      <td>-0.302314</td>\n",
       "      <td>-2.470564</td>\n",
       "      <td>2.274113</td>\n",
       "      <td>0.095904</td>\n",
       "      <td>-0.789807</td>\n",
       "      <td>0.060285</td>\n",
       "      <td>1.314964</td>\n",
       "      <td>0.511961</td>\n",
       "      <td>1.635200</td>\n",
       "      <td>-0.127105</td>\n",
       "      <td>-0.203623</td>\n",
       "      <td>0.754358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670639</td>\n",
       "      <td>0.375217</td>\n",
       "      <td>-0.609513</td>\n",
       "      <td>-0.316834</td>\n",
       "      <td>-0.212012</td>\n",
       "      <td>-0.295041</td>\n",
       "      <td>-0.039992</td>\n",
       "      <td>-0.546652</td>\n",
       "      <td>0.378768</td>\n",
       "      <td>1.085191</td>\n",
       "      <td>-0.553888</td>\n",
       "      <td>1.908566</td>\n",
       "      <td>-1.047519</td>\n",
       "      <td>0.615485</td>\n",
       "      <td>-0.860151</td>\n",
       "      <td>0.139610</td>\n",
       "      <td>1.235945</td>\n",
       "      <td>0.033071</td>\n",
       "      <td>0.318093</td>\n",
       "      <td>1.648370</td>\n",
       "      <td>0.038652</td>\n",
       "      <td>0.341122</td>\n",
       "      <td>1.150417</td>\n",
       "      <td>-0.462230</td>\n",
       "      <td>1.044938</td>\n",
       "      <td>-0.477347</td>\n",
       "      <td>1.489727</td>\n",
       "      <td>1.554991</td>\n",
       "      <td>-0.656179</td>\n",
       "      <td>-0.188854</td>\n",
       "      <td>-0.671738</td>\n",
       "      <td>-0.030108</td>\n",
       "      <td>1.525725</td>\n",
       "      <td>-0.075385</td>\n",
       "      <td>-1.121751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_attr_0  user_attr_1  ...  user_attr_33  user_attr_34\n",
       "0    -0.841159    -1.130349  ...     -0.416740     -0.193871\n",
       "1    -0.830372     0.358775  ...      0.433497     -0.167933\n",
       "2    -0.216478    -1.453142  ...      1.296526     -0.738848\n",
       "3     0.308584     0.786508  ...     -0.203623      0.754358\n",
       "4     0.670639     0.375217  ...     -0.075385     -1.121751\n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_gen.generate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_attr_0</th>\n",
       "      <th>item_attr_1</th>\n",
       "      <th>item_attr_2</th>\n",
       "      <th>item_attr_3</th>\n",
       "      <th>item_attr_4</th>\n",
       "      <th>item_attr_5</th>\n",
       "      <th>item_attr_6</th>\n",
       "      <th>item_attr_7</th>\n",
       "      <th>item_attr_8</th>\n",
       "      <th>item_attr_9</th>\n",
       "      <th>item_attr_10</th>\n",
       "      <th>item_attr_11</th>\n",
       "      <th>item_attr_12</th>\n",
       "      <th>item_attr_13</th>\n",
       "      <th>item_attr_14</th>\n",
       "      <th>item_attr_15</th>\n",
       "      <th>item_attr_16</th>\n",
       "      <th>item_attr_17</th>\n",
       "      <th>item_attr_18</th>\n",
       "      <th>item_attr_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.197979</td>\n",
       "      <td>1.491922</td>\n",
       "      <td>0.038514</td>\n",
       "      <td>1.293404</td>\n",
       "      <td>1.232039</td>\n",
       "      <td>2.690946</td>\n",
       "      <td>1.625152</td>\n",
       "      <td>0.857004</td>\n",
       "      <td>3.516270</td>\n",
       "      <td>1.097954</td>\n",
       "      <td>0.963833</td>\n",
       "      <td>1.820838</td>\n",
       "      <td>0.629233</td>\n",
       "      <td>0.712699</td>\n",
       "      <td>1.446134</td>\n",
       "      <td>1.217148</td>\n",
       "      <td>1.169454</td>\n",
       "      <td>1.154508</td>\n",
       "      <td>1.901708</td>\n",
       "      <td>0.950508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.573775</td>\n",
       "      <td>0.701697</td>\n",
       "      <td>1.798784</td>\n",
       "      <td>0.680811</td>\n",
       "      <td>-0.453520</td>\n",
       "      <td>2.658993</td>\n",
       "      <td>1.283767</td>\n",
       "      <td>0.249473</td>\n",
       "      <td>1.045836</td>\n",
       "      <td>2.980768</td>\n",
       "      <td>2.778132</td>\n",
       "      <td>0.219815</td>\n",
       "      <td>1.219519</td>\n",
       "      <td>1.873755</td>\n",
       "      <td>0.032647</td>\n",
       "      <td>3.095739</td>\n",
       "      <td>0.058625</td>\n",
       "      <td>1.561995</td>\n",
       "      <td>1.912624</td>\n",
       "      <td>0.791787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.172211</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.447960</td>\n",
       "      <td>0.303134</td>\n",
       "      <td>0.363194</td>\n",
       "      <td>2.610464</td>\n",
       "      <td>-0.269859</td>\n",
       "      <td>0.877516</td>\n",
       "      <td>3.306723</td>\n",
       "      <td>-0.260894</td>\n",
       "      <td>3.509923</td>\n",
       "      <td>0.347011</td>\n",
       "      <td>2.359311</td>\n",
       "      <td>1.154931</td>\n",
       "      <td>0.288173</td>\n",
       "      <td>1.367866</td>\n",
       "      <td>2.066255</td>\n",
       "      <td>1.233136</td>\n",
       "      <td>1.310583</td>\n",
       "      <td>0.343579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_attr_0  item_attr_1  ...  item_attr_18  item_attr_19\n",
       "0     1.197979     1.491922  ...      1.901708      0.950508\n",
       "1     1.573775     0.701697  ...      1.912624      0.791787\n",
       "2     1.172211     0.770769  ...      1.310583      0.343579\n",
       "\n",
       "[3 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_gen.generate(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator.utils import save\n",
    "\n",
    "save(user_gen, 'models/demo_user_gen.m')\n",
    "save(item_gen, 'models/demo_item_gen.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c23ac1ac3d03469769ffca4283c7852312778d94b2cbd9b1a60eeafc1c4055f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('simulator')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
